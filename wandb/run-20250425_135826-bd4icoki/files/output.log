[INFO    ][2025-04-25 13:58:27][__call__                 ] Loaded training params:
{'app': 'vjepa',
 'data': {'batch_size': 16,
          'clip_duration': None,
          'crop_size': 224,
          'dataset_type': 'VideoDataset',
          'datasets': ['~/saycam_files.csv'],
          'decode_one_clip': True,
          'filter_short_videos': False,
          'num_clips': 1,
          'num_frames': 16,
          'num_workers': 3,
          'patch_size': 16,
          'pin_mem': True,
          'sampling_rate': 4,
          'tubelet_size': 2},
 'data_aug': {'auto_augment': False,
              'motion_shift': False,
              'random_resize_aspect_ratio': [0.75, 1.35],
              'random_resize_scale': [0.3, 1.0],
              'reprob': 0.0},
 'logging': {'folder': '/scratch/eys8549/vjepa_training', 'write_tag': 'jepa'},
 'loss': {'loss_exp': 1.0, 'reg_coeff': 0.0},
 'mask': [{'aspect_ratio': [0.75, 1.5],
           'max_keep': None,
           'max_temporal_keep': 1.0,
           'num_blocks': 8,
           'spatial_scale': [0.15, 0.15],
           'temporal_scale': [1.0, 1.0]},
          {'aspect_ratio': [0.75, 1.5],
           'max_keep': None,
           'max_temporal_keep': 1.0,
           'num_blocks': 2,
           'spatial_scale': [0.7, 0.7],
           'temporal_scale': [1.0, 1.0]}],
 'meta': {'dtype': 'bfloat16',
          'eval_freq': 100,
          'load_checkpoint': False,
          'read_checkpoint': None,
          'seed': 234,
          'use_sdpa': True},
 'model': {'model_name': 'vit_large',
           'pred_depth': 12,
           'pred_embed_dim': 384,
           'uniform_power': True,
           'use_mask_tokens': True,
           'zero_init_mask_tokens': True},
 'nodes': 16,
 'optimization': {'clip_grad': 10.0,
                  'ema': [0.998, 1.0],
                  'epochs': 200,
                  'final_lr': 1e-06,
                  'final_weight_decay': 0.4,
                  'ipe': 300,
                  'ipe_scale': 1.25,
                  'lr': 0.000625,
                  'start_lr': 0.0002,
                  'warmup': 40,
                  'weight_decay': 0.04},
 'tasks_per_node': 8}
[INFO    ][2025-04-25 13:58:27][main                     ] Running pre-training of app: vjepa
[INFO    ][2025-04-25 13:58:35][main                     ] which_dtype='bfloat16'
[INFO    ][2025-04-25 13:58:35][main                     ] Initialized (rank/world-size) 1/2
[INFO    ][2025-04-25 13:58:35][main                     ] Rank 1 (local_rank 1) using device cuda:1
[INFO    ][2025-04-25 13:58:43][init_video_model         ] MultiMaskWrapper(
  (backbone): VisionTransformer(
    (patch_embed): PatchEmbed3D(
      (proj): Conv3d(3, 1024, kernel_size=(2, 16, 16), stride=(2, 16, 16))
    )
    (blocks): ModuleList(
      (0-23): 24 x Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  )
)
[INFO    ][2025-04-25 13:58:43][init_video_model         ] PredictorMultiMaskWrapper(
  (backbone): VisionTransformerPredictor(
    (predictor_embed): Linear(in_features=1024, out_features=384, bias=True)
    (mask_tokens): ParameterList(
        (0): Parameter containing: [torch.float32 of size 1x1x384 (cuda:1)]
        (1): Parameter containing: [torch.float32 of size 1x1x384 (cuda:1)]
    )
    (predictor_blocks): ModuleList(
      (0-11): 12 x Block(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (predictor_norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
    (predictor_proj): Linear(in_features=384, out_features=1024, bias=True)
  )
)
[INFO    ][2025-04-25 13:58:43][init_video_model         ] Encoder number of parameters: 303885312
[INFO    ][2025-04-25 13:58:43][init_video_model         ] Predictor number of parameters: 22082944
[INFO    ][2025-04-25 13:58:43][main                     ] Initializing basic multi-block mask
[INFO    ][2025-04-25 13:58:46][make_videodataset        ] VideoDataset dataset created
[INFO    ][2025-04-25 13:58:46][make_videodataset        ] VideoDataset unsupervised data loader created
[INFO    ][2025-04-25 13:58:46][main                     ] iterations per epoch/dataest length: 300/326
[INFO    ][2025-04-25 13:58:46][init_opt                 ] Using AdamW
/home/eys8549/vjepa/app/vjepa/utils.py:209: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler() if mixed_precision else None
/home/eys8549/miniconda3/envs/vjepa/lib/python3.11/site-packages/torch/nn/parallel/distributed.py:2351: UserWarning: You passed find_unused_parameters=true to DistributedDataParallel, `_set_static_graph` will detect unused parameters automatically, so you do not need to set find_unused_parameters=true, just be sure these unused parameters will not change during training loop while calling `_set_static_graph`.
  warnings.warn(
[INFO    ][2025-04-25 13:58:47][main                     ] Initializing loader...
[INFO    ][2025-04-25 13:59:07][main                     ] Epoch 1
/home/eys8549/vjepa/app/vjepa/train.py:472: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(dtype=dtype, enabled=mixed_precision):
/home/eys8549/miniconda3/envs/vjepa/lib/python3.11/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
[INFO    ][2025-04-25 13:59:19][log_stats                ] [1,     0] loss: 0.862 | p0.862 r0.820 | input_var: 1.271 0.286 | masks: [400.0, 112.0] [wd: 4.00e-02] [lr: 2.00e-04] [mem: 1.92e+04] [gpu: 4087.5 ms][wall: 11908.8 ms]
[INFO    ][2025-04-25 13:59:19][log_stats                ] [1,     0] first moment: 5.20e-06 [1.04e-07 6.19e-05] second moment: 2.55e-11 [6.00e-15 6.03e-10]
[INFO    ][2025-04-25 13:59:19][log_stats                ] [1,     0] enc_grad_stats: f/l[9.62e-03 4.37e-03] mn/mx(4.37e-03, 1.74e-02) 0.00e+00
[INFO    ][2025-04-25 13:59:19][log_stats                ] [1,     0] pred_grad_stats: f/l[9.47e-02 5.73e-02] mn/mx(6.88e-03, 3.24e-01) 0.00e+00
